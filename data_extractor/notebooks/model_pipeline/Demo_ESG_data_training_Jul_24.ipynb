{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:52:20 - INFO - transformers.file_utils -   PyTorch version 1.5.0 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from model_pipeline import FARMTrainer\n",
    "from model_pipeline import ModelConfig, TokenizerConfig, TrainingConfig, FileConfig, MLFlowConfig, ProcessorConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline trains the relevance classifier once the dataset has been extracted and curated. The model trained is comprised of a transformer model (e.g., BERT) that can be loaded pre-trained on the NQ dataset into the pipeline and then be fine-tuned on the curated data for our specific relevance detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline includes components that are provided by the FARM library. FARM is a framework which facilitates transfer learning tasks for BERT based models. Documentation for FARM is available here: https://farm.deepset.ai.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our demo, we use the curated data generated after receiving the latest set of annotations provided by the Allianz ESG team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting training, parameters for each component of the training pipeline must be set. For this we create `config` objects which hold these parameters. Default values have already been set but they can be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = FileConfig()  # Settings data files and checkpoints parameters\n",
    "processor_config = ProcessorConfig()  # Settings for the processor component\n",
    "tokenizer_config = TokenizerConfig()  # Settings for the tokenizer\n",
    "model_config = ModelConfig()  # Settings for the model\n",
    "train_config = TrainingConfig()  # Settings for training\n",
    "mlflow_config = MLFlowConfig()  # Settings for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be changed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config.experiment_name = \"demo_training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we advise that you manually update the parameters in the corresponding config file:\n",
    "\n",
    "`esg_data_pipeline/config/config_farm_trainer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the value for some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_name: \n",
      " demo_training \n",
      "\n",
      "Data directory: \n",
      " /model_pipeline/model_pipeline/data \n",
      "\n",
      "Curated dataset path: \n",
      " /model_pipeline/model_pipeline/data/esg_dataset.csv \n",
      "\n",
      "Split train/validation ratio: \n",
      "0.2 \n",
      "\n",
      "Training dataset path: \n",
      " /model_pipeline/model_pipeline/data/train_split_02.csv \n",
      "\n",
      "Validation dataset path: \n",
      " /model_pipeline/model_pipeline/data/val_split_02.csv \n",
      "\n",
      "Directory where trained model is saved: \n",
      " saved_models/test_farm \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment_name: \\n {file_config.experiment_name} \\n\")\n",
    "print(f\"Data directory: \\n {file_config.data_dir} \\n\")\n",
    "print(f\"Curated dataset path: \\n {file_config.curated_data} \\n\")\n",
    "print(f\"Split train/validation ratio: \\n{file_config.test_split} \\n\")\n",
    "print(f\"Training dataset path: \\n {file_config.train_filename} \\n\")\n",
    "print(f\"Validation dataset path: \\n {file_config.dev_filename} \\n\")\n",
    "print(f\"Directory where trained model is saved: \\n {file_config.saved_models_dir} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens per example: 512 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max number of tokens per example: {processor_config.max_seq_len} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Use GPU: {train_config.use_cuda} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 1e-05 \n",
      "\n",
      "Number of epochs for fine tuning: 1 \n",
      "\n",
      "Batch size: 16 \n",
      "\n",
      "Perform Cross validation: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Learning_rate: {train_config.learning_rate} \\n\")\n",
    "print(f\"Number of epochs for fine tuning: {train_config.n_epochs} \\n\")\n",
    "print(f\"Batch size: {train_config.batch_size} \\n\")\n",
    "print(f\"Perform Cross validation: {train_config.run_cv} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model trained on NQ dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already trained a relevance classifier on Google's large NQ dataset. We then saved the model in the following directory: `file_config.saved_models_dir / \"relevance_roberta\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load this model in our pipeline to fine-tune a relevance classifier on our specific ESG curated dataset. For this we have to set the parameter `model_config.load_dir` to be the directory where we saved our first checkpoint. We can check that this is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQ checkpoint directory: /model_pipeline/model_pipeline/saved_models/relevance_roberta\n"
     ]
    }
   ],
   "source": [
    "print(f\"NQ checkpoint directory: {model_config.load_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune on curated ESG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the parameters are set a `FARMTrainer` object can be instantiated by passing all the configuration objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method `run()` to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:52:32 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/24/2020 03:52:32 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/24/2020 03:52:33 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "07/24/2020 03:52:33 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2020/07/24 03:52:33 WARNING mlflow.tracking.context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -   Loading train set from: /model_pipeline/model_pipeline/data/train_split_02.csv \n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -   Got ya 15 parallel workers to convert 1196 dictionaries to pytorch datasets (chunksize = 16)...\n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -   /|\\  /|\\  /|\\  /w\\  /|\\  /w\\  /w\\  /|\\  /w\\  /|\\  /w\\  /w\\  /w\\  /|\\  /|\\\n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  / \\  /'\\  /'\\\n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.data_silo -                               \n",
      "Preprocessing Dataset /model_pipeline/model_pipeline/data/train_split_02.csv:   0%|          | 0/1196 [00:00<?, ? Dicts/s]07/24/2020 03:52:34 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:52:34 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 8-0\n",
      "Clear Text: \n",
      " \ttext: What is the company name?\n",
      " \ttext_b: Adani Power Limited\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġcompany', 'Ġname', '?']\n",
      " \ttokens_b: ['Ad', 'ani', 'ĠPower', 'ĠLimited']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 138, 766, 116, 2, 2, 9167, 1543, 3029, 5266, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:52:34 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 2-0\n",
      "Clear Text: \n",
      " \ttext: What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?\n",
      " \ttext_b: Breakdown of petroleum products delivery to consignees\n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġamount', 'Ġof', 'Ġdirect', 'Ġgreenhouse', 'Ġgases', 'Ġemissions', 'Ġreferred', 'Ġto', 'Ġas', 'Ġscope', 'Ġ1', 'Ġemissions', '?']\n",
      " \ttokens_b: ['Break', 'down', 'Ġof', 'Ġpetroleum', 'Ġproducts', 'Ġdelivery', 'Ġto', 'Ġcons', 'ign', 'ees']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 1280, 9, 2228, 11832, 20038, 5035, 4997, 7, 25, 7401, 112, 5035, 116, 2, 2, 39539, 3955, 9, 14304, 785, 2996, 7, 7407, 4932, 5421, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /model_pipeline/model_pipeline/data/train_split_02.csv: 100%|██████████| 1196/1196 [00:06<00:00, 192.53 Dicts/s]\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -   Loading dev set from: /model_pipeline/model_pipeline/data/val_split_02.csv\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -   Got ya 15 parallel workers to convert 300 dictionaries to pytorch datasets (chunksize = 4)...\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -   /|\\  /w\\  /|\\  /w\\  /w\\  /|\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.data_silo -                               \n",
      "Preprocessing Dataset /model_pipeline/model_pipeline/data/val_split_02.csv:   0%|          | 0/300 [00:00<?, ? Dicts/s]07/24/2020 03:52:40 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:52:40 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the company name?\n",
      " \ttext_b: The appeal before the Court of Cassation has not yet be scheduled. In March 2013, the legal representative of Saipem Contracting Algrie was summoned to appear at the Court of Algiers, where he received verbal notification from the local investigating judge of the commencement of an investigation (‘Sonatrach 2’) underway ‘into Saipem for charges pursuant to Articles 25a, 32 and 53 of Anti-Corruption Law No. 01/2006’. The investigating judge also requested documentation (Articles of Association) and other information concerning Saipem Contracting Algrie, Saipem and Saipem SA. Amicable Settlement of Mutual Differences - Saipem Sonatrach agreement - Press Release of February 14, 2018: on February 14, 2018, the following joint press release was issued. Sonatrach and Saipem announce the amicable settlement of mutual differences. San Donato Milanese (MI), February 14, 2018 - Sonatrach and Saipem have decided to settle their mutual differences amicably and have signed an agreement to put an end to litigations in course concerning the contract for the construction of a gas liquefaction plant in Arzew (Arzew); the contract for the realisation of three trains of LPG, of an oil separation unit (LDPH) and of installations for the production of condensates in Hassi Messaoud (LPG); the contract for the realisation of the LZ2 24’’ LPG\n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġcompany', 'Ġname', '?']\n",
      " \ttokens_b: ['The', 'Ġappeal', 'Ġbefore', 'Ġthe', 'ĠCourt', 'Ġof', 'ĠCass', 'ation', 'Ġhas', 'Ġnot', 'Ġyet', 'Ġbe', 'Ġscheduled', '.', 'ĠIn', 'ĠMarch', 'Ġ2013', ',', 'Ġthe', 'Ġlegal', 'Ġrepresentative', 'Ġof', 'ĠSa', 'ip', 'em', 'ĠContract', 'ing', 'ĠAl', 'g', 'rie', 'Ġwas', 'Ġsummoned', 'Ġto', 'Ġappear', 'Ġat', 'Ġthe', 'ĠCourt', 'Ġof', 'ĠAl', 'g', 'iers', ',', 'Ġwhere', 'Ġhe', 'Ġreceived', 'Ġverbal', 'Ġnotification', 'Ġfrom', 'Ġthe', 'Ġlocal', 'Ġinvestigating', 'Ġjudge', 'Ġof', 'Ġthe', 'Ġcommencement', 'Ġof', 'Ġan', 'Ġinvestigation', 'Ġ(', 'âĢ', 'ĺ', 'Son', 'at', 'r', 'ach', 'Ġ2', 'âĢ', 'Ļ', ')', 'Ġunderway', 'ĠâĢ', 'ĺ', 'into', 'ĠSa', 'ip', 'em', 'Ġfor', 'Ġcharges', 'Ġpursuant', 'Ġto', 'ĠArticles', 'Ġ25', 'a', ',', 'Ġ32', 'Ġand', 'Ġ53', 'Ġof', 'ĠAnti', '-', 'Cor', 'ruption', 'ĠLaw', 'ĠNo', '.', 'Ġ01', '/', '2006', 'âĢ', 'Ļ', '.', 'ĠThe', 'Ġinvestigating', 'Ġjudge', 'Ġalso', 'Ġrequested', 'Ġdocumentation', 'Ġ(', 'Art', 'icles', 'Ġof', 'ĠAssociation', ')', 'Ġand', 'Ġother', 'Ġinformation', 'Ġconcerning', 'ĠSa', 'ip', 'em', 'ĠContract', 'ing', 'ĠAl', 'g', 'rie', ',', 'ĠSa', 'ip', 'em', 'Ġand', 'ĠSa', 'ip', 'em', 'ĠSA', '.', 'ĠAm', 'icable', 'ĠSettlement', 'Ġof', 'ĠMutual', 'ĠDifferences', 'Ġ-', 'ĠSa', 'ip', 'em', 'ĠSon', 'at', 'r', 'ach', 'Ġagreement', 'Ġ-', 'ĠPress', 'ĠRelease', 'Ġof', 'ĠFebruary', 'Ġ14', ',', 'Ġ2018', ':', 'Ġon', 'ĠFebruary', 'Ġ14', ',', 'Ġ2018', ',', 'Ġthe', 'Ġfollowing', 'Ġjoint', 'Ġpress', 'Ġrelease', 'Ġwas', 'Ġissued', '.', 'ĠSon', 'at', 'r', 'ach', 'Ġand', 'ĠSa', 'ip', 'em', 'Ġannounce', 'Ġthe', 'Ġam', 'icable', 'Ġsettlement', 'Ġof', 'Ġmutual', 'Ġdifferences', '.', 'ĠSan', 'ĠDon', 'ato', 'ĠMilan', 'ese', 'Ġ(', 'MI', '),', 'ĠFebruary', 'Ġ14', ',', 'Ġ2018', 'Ġ-', 'ĠSon', 'at', 'r', 'ach', 'Ġand', 'ĠSa', 'ip', 'em', 'Ġhave', 'Ġdecided', 'Ġto', 'Ġsettle', 'Ġtheir', 'Ġmutual', 'Ġdifferences', 'Ġam', 'icably', 'Ġand', 'Ġhave', 'Ġsigned', 'Ġan', 'Ġagreement', 'Ġto', 'Ġput', 'Ġan', 'Ġend', 'Ġto', 'Ġlit', 'ig', 'ations', 'Ġin', 'Ġcourse', 'Ġconcerning', 'Ġthe', 'Ġcontract', 'Ġfor', 'Ġthe', 'Ġconstruction', 'Ġof', 'Ġa', 'Ġgas', 'Ġliqu', 'ef', 'action', 'Ġplant', 'Ġin', 'ĠAr', 'z', 'ew', 'Ġ(', 'Ar', 'z', 'ew', ');', 'Ġthe', 'Ġcontract', 'Ġfor', 'Ġthe', 'Ġreal', 'isation', 'Ġof', 'Ġthree', 'Ġtrains', 'Ġof', 'ĠL', 'PG', ',', 'Ġof', 'Ġan', 'Ġoil', 'Ġseparation', 'Ġunit', 'Ġ(', 'L', 'DP', 'H', ')', 'Ġand', 'Ġof', 'Ġinstallations', 'Ġfor', 'Ġthe', 'Ġproduction', 'Ġof', 'Ġcond', 'ens', 'ates', 'Ġin', 'ĠHass', 'i', 'ĠMess', 'a', 'oud', 'Ġ(', 'L', 'PG', ');', 'Ġthe', 'Ġcontract', 'Ġfor', 'Ġthe', 'Ġreal', 'isation', 'Ġof', 'Ġthe', 'ĠL', 'Z', '2', 'Ġ24', 'âĢ', 'Ļ', 'âĢ', 'Ļ', 'ĠL', 'PG']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 138, 766, 116, 2, 2, 133, 2868, 137, 5, 837, 9, 11710, 1258, 34, 45, 648, 28, 1768, 4, 96, 494, 1014, 6, 5, 1030, 4915, 9, 4141, 1588, 991, 15739, 154, 726, 571, 3636, 21, 17323, 7, 2082, 23, 5, 837, 9, 726, 571, 4733, 6, 147, 37, 829, 14580, 12059, 31, 5, 400, 3219, 1679, 9, 5, 23666, 9, 41, 803, 36, 17, 711, 29111, 415, 338, 1488, 132, 17, 27, 43, 6159, 44, 711, 12473, 4141, 1588, 991, 13, 1103, 22918, 7, 15219, 564, 102, 6, 2107, 8, 4268, 9, 9511, 12, 15228, 26858, 2589, 440, 4, 9465, 73, 32701, 17, 27, 4, 20, 3219, 1679, 67, 5372, 14877, 36, 23295, 20846, 9, 1544, 43, 8, 97, 335, 8082, 4141, 1588, 991, 15739, 154, 726, 571, 3636, 6, 4141, 1588, 991, 8, 4141, 1588, 991, 5531, 4, 1918, 26092, 33629, 9, 21248, 44444, 111, 4141, 1588, 991, 4969, 415, 338, 1488, 1288, 111, 977, 15781, 9, 902, 501, 6, 199, 35, 15, 902, 501, 6, 199, 6, 5, 511, 2660, 1228, 800, 21, 1167, 4, 4969, 415, 338, 1488, 8, 4141, 1588, 991, 4659, 5, 524, 26092, 4221, 9, 7628, 5550, 4, 764, 1599, 3938, 7338, 4468, 36, 7539, 238, 902, 501, 6, 199, 111, 4969, 415, 338, 1488, 8, 4141, 1588, 991, 33, 1276, 7, 6307, 49, 7628, 5550, 524, 31249, 8, 33, 1419, 41, 1288, 7, 342, 41, 253, 7, 6474, 1023, 1635, 11, 768, 8082, 5, 1355, 13, 5, 1663, 9, 10, 1123, 23321, 4550, 10845, 2195, 11, 1586, 329, 2753, 36, 8138, 329, 2753, 4397, 5, 1355, 13, 5, 588, 3258, 9, 130, 7717, 9, 226, 8332, 6, 9, 41, 681, 10875, 1933, 36, 574, 5174, 725, 43, 8, 9, 19468, 13, 5, 931, 9, 10022, 1290, 1626, 11, 27542, 118, 15212, 102, 6998, 36, 574, 8332, 4397, 5, 1355, 13, 5, 588, 3258, 9, 5, 226, 1301, 176, 706, 17, 27, 17, 27, 226, 8332, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:52:40 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1-0\n",
      "Clear Text: \n",
      " \ttext: What is the total volume of hydrocarbons production?\n",
      " \ttext_b: Our regulations and measures for transportation and warehouse safety cover the delivery of raw materials, the storage and distribution of chemical products among BASF sites and customers, and the transportation of waste from our sites to the disposal facilities.\n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġvolume', 'Ġof', 'Ġhydro', 'car', 'bons', 'Ġproduction', '?']\n",
      " \ttokens_b: ['Our', 'Ġregulations', 'Ġand', 'Ġmeasures', 'Ġfor', 'Ġtransportation', 'Ġand', 'Ġwarehouse', 'Ġsafety', 'Ġcover', 'Ġthe', 'Ġdelivery', 'Ġof', 'Ġraw', 'Ġmaterials', ',', 'Ġthe', 'Ġstorage', 'Ġand', 'Ġdistribution', 'Ġof', 'Ġchemical', 'Ġproducts', 'Ġamong', 'ĠBAS', 'F', 'Ġsites', 'Ġand', 'Ġcustomers', ',', 'Ġand', 'Ġthe', 'Ġtransportation', 'Ġof', 'Ġwaste', 'Ġfrom', 'Ġour', 'Ġsites', 'Ġto', 'Ġthe', 'Ġdisposal', 'Ġfacilities', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 3149, 9, 13575, 5901, 16830, 931, 116, 2, 2, 2522, 3478, 8, 1797, 13, 4264, 8, 12283, 1078, 1719, 5, 2996, 9, 6087, 3183, 6, 5, 3521, 8, 3854, 9, 4747, 785, 566, 17430, 597, 3091, 8, 916, 6, 8, 5, 4264, 9, 3844, 31, 84, 3091, 7, 5, 12307, 2644, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /model_pipeline/model_pipeline/data/val_split_02.csv: 100%|██████████| 300/300 [00:06<00:00, 48.58 Dicts/s]\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Examples in train: 1196\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Examples in dev  : 300\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   \n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     512\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 68.60367892976589\n",
      "07/24/2020 03:52:47 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.0016722408026755853\n",
      "07/24/2020 03:52:47 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 03:52:47 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "07/24/2020 03:52:53 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 03:52:53 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 03:52:53 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:52:56 - INFO - transformers.modeling_utils -   loading weights file /model_pipeline/model_pipeline/saved_models/relevance_roberta/language_model.bin from cache at /model_pipeline/model_pipeline/saved_models/relevance_roberta/language_model.bin\n",
      "07/24/2020 03:53:01 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 03:53:01 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at /model_pipeline/model_pipeline/saved_models/relevance_roberta/language_model.bin.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/24/2020 03:53:01 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.prediction_head -   Loading prediction head from /model_pipeline/model_pipeline/saved_models/relevance_roberta/prediction_head_0.bin\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/24/2020 03:53:01 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 7.5, 'num_training_steps': 75}'\n",
      "07/24/2020 03:53:02 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.6335):  40%|████      | 30/75 [00:31<00:38,  1.17it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:05<00:00,  3.77it/s]\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   loss: 0.3626940894126892\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   acc: 0.8366666666666667\n",
      "07/24/2020 03:53:39 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9516    0.7329    0.8281       161\n",
      "           1     0.7557    0.9568    0.8444       139\n",
      "\n",
      "    accuracy                         0.8367       300\n",
      "   macro avg     0.8536    0.8449    0.8363       300\n",
      "weighted avg     0.8608    0.8367    0.8357       300\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.1016):  80%|████████  | 60/75 [01:01<00:12,  1.21it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:05<00:00,  3.77it/s]\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   loss: 0.2670291393995285\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   acc: 0.9166666666666666\n",
      "07/24/2020 03:54:09 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9416    0.9006    0.9206       161\n",
      "           1     0.8904    0.9353    0.9123       139\n",
      "\n",
      "    accuracy                         0.9167       300\n",
      "   macro avg     0.9160    0.9179    0.9165       300\n",
      "weighted avg     0.9179    0.9167    0.9168       300\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0290): 100%|██████████| 75/75 [01:19<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 19/19 [00:05<00:00,  3.76it/s]\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 19 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   loss: 0.23336737950642902\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   acc: 0.9366666666666666\n",
      "07/24/2020 03:54:26 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9437    0.9379    0.9408       161\n",
      "           1     0.9286    0.9353    0.9319       139\n",
      "\n",
      "    accuracy                         0.9367       300\n",
      "   macro avg     0.9362    0.9366    0.9364       300\n",
      "weighted avg     0.9367    0.9367    0.9367       300\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved to saved_models/test_farm\n",
      "Processor vocabulary saved to saved_models/test_farm\n"
     ]
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training process, the model and the processor vocabulary are saved into the directory `file_config.saved_models_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 488308\r\n",
      "drwxr-xr-x 2 root root      4096 Jul 24 03:54 .\r\n",
      "drwxr-xr-x 3 root root      4096 Jul 24 03:54 ..\r\n",
      "-rw-r--r-- 1 root root 498630327 Jul 24 03:54 language_model.bin\r\n",
      "-rw-r--r-- 1 root root       562 Jul 24 03:54 language_model_config.json\r\n",
      "-rw-r--r-- 1 root root    456318 Jul 24 03:54 merges.txt\r\n",
      "-rw-r--r-- 1 root root      6879 Jul 24 03:54 prediction_head_0.bin\r\n",
      "-rw-r--r-- 1 root root       556 Jul 24 03:54 prediction_head_0_config.json\r\n",
      "-rw-r--r-- 1 root root       727 Jul 24 03:54 processor_config.json\r\n",
      "-rw-r--r-- 1 root root       772 Jul 24 03:54 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root       167 Jul 24 03:54 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root    898822 Jul 24 03:54 vocab.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better estimate the performance of the model on new data, it is recommended to perform k-folds cross validation (CV). CV works as follows:\n",
    "\n",
    "- Split the entire data randomly into k folds (usually 5 to 10)\n",
    "- Fit the model using the K — 1 folds and validate the model using the remaining Kth fold and save the scores\n",
    "- Repeat until every K-fold serve as the test set and average the saved scores\n",
    "\n",
    "_FARMTrainer_ includes this features. To perform 3-fold CV proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config.run_cv = True\n",
    "train_config.xval_folds = 3\n",
    "train_config.n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:00:27 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/24/2020 01:00:27 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/24/2020 01:00:27 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ehsanmontazeri/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "07/24/2020 01:00:27 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ehsanmontazeri/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -   Loading train set from: /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/train_split_02.csv \n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -   Got ya 3 parallel workers to convert 1196 dictionaries to pytorch datasets (chunksize = 80)...\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -    0    0    0 \n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -   /|\\  /|\\  /|\\\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.data_silo -       \n",
      "Preprocessing Dataset /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/train_split_02.csv:   0%|          | 0/1196 [00:00<?, ? Dicts/s]07/24/2020 01:00:28 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 22-0\n",
      "Clear Text: \n",
      " \ttext: What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?\n",
      " \ttext_b: LUKOIL has been participating in the Carbon Disclosure Project (CDP), an international initiative for the disclosure of greenhouse gas emissions. \n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġamount', 'Ġof', 'Ġdirect', 'Ġgreenhouse', 'Ġgases', 'Ġemissions', 'Ġreferred', 'Ġto', 'Ġas', 'Ġscope', 'Ġ1', 'Ġemissions', '?']\n",
      " \ttokens_b: ['L', 'UK', 'OIL', 'Ġhas', 'Ġbeen', 'Ġparticipating', 'Ġin', 'Ġthe', 'ĠCarbon', 'ĠDisclosure', 'ĠProject', 'Ġ(', 'C', 'DP', '),', 'Ġan', 'Ġinternational', 'Ġinitiative', 'Ġfor', 'Ġthe', 'Ġdisclosure', 'Ġof', 'Ġgreenhouse', 'Ġgas', 'Ġemissions', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 1280, 9, 2228, 11832, 20038, 5035, 4997, 7, 25, 7401, 112, 5035, 116, 2, 2, 574, 10494, 41382, 34, 57, 6051, 11, 5, 17962, 15576, 3728, 36, 347, 5174, 238, 41, 758, 3893, 13, 5, 6262, 9, 11832, 1123, 5035, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/24/2020 01:00:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 21-0\n",
      "Clear Text: \n",
      " \ttext: What is the total volume of hydrocarbons production?\n",
      " \ttext_b: For the full-year 2016, hydrocarbon production was 2,452 kboe/d, an increase of 4.5% compared to 2,347 kboe/d in 2015, due to the following:\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġvolume', 'Ġof', 'Ġhydro', 'car', 'bons', 'Ġproduction', '?']\n",
      " \ttokens_b: ['For', 'Ġthe', 'Ġfull', '-', 'year', 'Ġ2016', ',', 'Ġhydro', 'carbon', 'Ġproduction', 'Ġwas', 'Ġ2', ',', '452', 'Ġk', 'bo', 'e', '/', 'd', ',', 'Ġan', 'Ġincrease', 'Ġof', 'Ġ4', '.', '5', '%', 'Ġcompared', 'Ġto', 'Ġ2', ',', '347', 'Ġk', 'bo', 'e', '/', 'd', 'Ġin', 'Ġ2015', ',', 'Ġdue', 'Ġto', 'Ġthe', 'Ġfollowing', ':']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 3149, 9, 13575, 5901, 16830, 931, 116, 2, 2, 2709, 5, 455, 12, 180, 336, 6, 13575, 23612, 931, 21, 132, 6, 36720, 449, 3983, 242, 73, 417, 6, 41, 712, 9, 204, 4, 245, 207, 1118, 7, 132, 6, 32532, 449, 3983, 242, 73, 417, 11, 570, 6, 528, 7, 5, 511, 35, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________\n",
      "Preprocessing Dataset /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/train_split_02.csv: 100%|██████████| 1196/1196 [00:03<00:00, 390.09 Dicts/s]\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -   Loading dev set from: /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/val_split_02.csv\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -   Got ya 3 parallel workers to convert 300 dictionaries to pytorch datasets (chunksize = 20)...\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -    0    0    0 \n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -   /w\\  /|\\  /w\\\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -   / \\  /'\\  /'\\\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.data_silo -       \n",
      "Preprocessing Dataset /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/val_split_02.csv:   0%|          | 0/300 [00:00<?, ? Dicts/s]07/24/2020 01:00:31 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 8-0\n",
      "Clear Text: \n",
      " \ttext: What is the base year for carbon reduction commitment?\n",
      " \ttext_b: At the Committee’s discretion, the Company may also agree other payments such as an agreed amount for legal fees associated with the departure of the Executive Director and outplacement support. \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġfor', 'Ġcarbon', 'Ġreduction', 'Ġcommitment', '?']\n",
      " \ttokens_b: ['At', 'Ġthe', 'ĠCommittee', 'âĢ', 'Ļ', 's', 'Ġdiscretion', ',', 'Ġthe', 'ĠCompany', 'Ġmay', 'Ġalso', 'Ġagree', 'Ġother', 'Ġpayments', 'Ġsuch', 'Ġas', 'Ġan', 'Ġagreed', 'Ġamount', 'Ġfor', 'Ġlegal', 'Ġfees', 'Ġassociated', 'Ġwith', 'Ġthe', 'Ġdeparture', 'Ġof', 'Ġthe', 'ĠExecutive', 'ĠDirector', 'Ġand', 'Ġout', 'pl', 'acement', 'Ġsupport', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 13, 4363, 4878, 2720, 116, 2, 2, 3750, 5, 1674, 17, 27, 29, 14145, 6, 5, 1260, 189, 67, 2854, 97, 3081, 215, 25, 41, 1507, 1280, 13, 1030, 3154, 3059, 19, 5, 5824, 9, 5, 2483, 1678, 8, 66, 2911, 23423, 323, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "07/24/2020 01:00:31 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 19-0\n",
      "Clear Text: \n",
      " \ttext: In which year was the annual report or the sustainability report published?\n",
      " \ttext_b: 2015 ANNUAL REPORT AND ACCOUNTS\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['In', 'Ġwhich', 'Ġyear', 'Ġwas', 'Ġthe', 'Ġannual', 'Ġreport', 'Ġor', 'Ġthe', 'Ġsustainability', 'Ġreport', 'Ġpublished', '?']\n",
      " \ttokens_b: ['2015', 'ĠANN', 'UAL', 'ĠREPORT', 'ĠAND', 'ĠACC', 'OUN', 'TS']\n",
      "Features: \n",
      " \tinput_ids: [0, 1121, 61, 76, 21, 5, 1013, 266, 50, 5, 11128, 266, 1027, 116, 2, 2, 14420, 31256, 17710, 13060, 4248, 10018, 30696, 2685, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________\n",
      "Preprocessing Dataset /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/data/val_split_02.csv: 100%|██████████| 300/300 [00:01<00:00, 225.69 Dicts/s]\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Examples in train: 1196\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Examples in dev  : 300\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   \n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     512\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 68.60367892976589\n",
      "07/24/2020 01:00:33 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.0016722408026755853\n",
      "07/24/2020 01:00:33 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Crossvalidation: Fold 0 ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:00:33 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ehsanmontazeri/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "07/24/2020 01:00:38 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:00:38 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:00:38 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/24/2020 01:00:38 - INFO - transformers.modeling_utils -   loading weights file /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin from cache at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin\n",
      "07/24/2020 01:00:43 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:00:43 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/24/2020 01:00:43 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.prediction_head -   Loading prediction head from /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/prediction_head_0.bin\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/24/2020 01:00:43 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 15.0, 'num_training_steps': 150}'\n",
      "07/24/2020 01:00:43 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.1461):  60%|██████    | 30/50 [00:25<00:16,  1.20it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   loss: 0.21454130435109736\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   acc: 0.9447236180904522\n",
      "07/24/2020 01:01:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.9358    0.9488       109\n",
      "           1     0.9247    0.9556    0.9399        90\n",
      "\n",
      "    accuracy                         0.9447       199\n",
      "   macro avg     0.9435    0.9457    0.9444       199\n",
      "weighted avg     0.9453    0.9447    0.9448       199\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.0527): 100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Train epoch 1/2 (Cur. train loss: 0.0962):  20%|██        | 10/50 [00:08<00:32,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   loss: 0.3312465611414694\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   acc: 0.9296482412060302\n",
      "07/24/2020 01:01:40 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9798    0.8899    0.9327       109\n",
      "           1     0.8800    0.9778    0.9263        90\n",
      "\n",
      "    accuracy                         0.9296       199\n",
      "   macro avg     0.9299    0.9338    0.9295       199\n",
      "weighted avg     0.9347    0.9296    0.9298       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.2546):  80%|████████  | 40/50 [00:35<00:08,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 90 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   loss: 0.23712759551091409\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   acc: 0.949748743718593\n",
      "07/24/2020 01:02:08 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9083    0.9519       109\n",
      "           1     0.9000    1.0000    0.9474        90\n",
      "\n",
      "    accuracy                         0.9497       199\n",
      "   macro avg     0.9500    0.9541    0.9496       199\n",
      "weighted avg     0.9548    0.9497    0.9499       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.0025): 100%|██████████| 50/50 [00:47<00:00,  1.06it/s]\n",
      "Train epoch 2/2 (Cur. train loss: 0.0060):  40%|████      | 20/50 [00:16<00:24,  1.25it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n",
      "07/24/2020 01:02:35 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 120 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:02:35 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:02:35 - INFO - farm.eval -   loss: 0.22316187410498384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:02:35 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:02:35 - INFO - farm.eval -   acc: 0.9396984924623115\n",
      "07/24/2020 01:02:35 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9450    0.9450    0.9450       109\n",
      "           1     0.9333    0.9333    0.9333        90\n",
      "\n",
      "    accuracy                         0.9397       199\n",
      "   macro avg     0.9391    0.9391    0.9391       199\n",
      "weighted avg     0.9397    0.9397    0.9397       199\n",
      "\n",
      "Train epoch 2/2 (Cur. train loss: 0.0076): 100%|██████████| 50/50 [00:43<00:00,  1.15it/s]\n",
      "Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   loss: 0.2763407023731836\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   acc: 0.9498997995991983\n",
      "07/24/2020 01:03:07 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9441    0.9677    0.9558       279\n",
      "           1     0.9577    0.9273    0.9423       220\n",
      "\n",
      "    accuracy                         0.9499       499\n",
      "   macro avg     0.9509    0.9475    0.9490       499\n",
      "weighted avg     0.9501    0.9499    0.9498       499\n",
      "\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:03:10 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Crossvalidation: Fold 1 ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:03:11 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ehsanmontazeri/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "07/24/2020 01:03:15 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:03:15 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:03:15 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/24/2020 01:03:16 - INFO - transformers.modeling_utils -   loading weights file /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin from cache at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin\n",
      "07/24/2020 01:03:20 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:03:20 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:03:20 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/24/2020 01:03:20 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/24/2020 01:03:20 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 01:03:20 - INFO - farm.modeling.prediction_head -   Loading prediction head from /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/prediction_head_0.bin\n",
      "07/24/2020 01:03:21 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/24/2020 01:03:21 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/24/2020 01:03:21 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 15.0, 'num_training_steps': 150}'\n",
      "07/24/2020 01:03:21 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.1729):  60%|██████    | 30/50 [00:25<00:16,  1.20it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   loss: 0.2952238252414531\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   acc: 0.914572864321608\n",
      "07/24/2020 01:03:50 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9238    0.9151    0.9194       106\n",
      "           1     0.9043    0.9140    0.9091        93\n",
      "\n",
      "    accuracy                         0.9146       199\n",
      "   macro avg     0.9140    0.9145    0.9143       199\n",
      "weighted avg     0.9147    0.9146    0.9146       199\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.0724): 100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Train epoch 1/2 (Cur. train loss: 0.0389):  20%|██        | 10/50 [00:08<00:32,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.87it/s]\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   loss: 0.47910682460171494\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   acc: 0.8994974874371859\n",
      "07/24/2020 01:04:18 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8468    0.9906    0.9130       106\n",
      "           1     0.9867    0.7957    0.8810        93\n",
      "\n",
      "    accuracy                         0.8995       199\n",
      "   macro avg     0.9167    0.8931    0.8970       199\n",
      "weighted avg     0.9122    0.8995    0.8980       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.0006):  80%|████████  | 40/50 [00:35<00:08,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 90 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   loss: 0.46165254906793335\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   acc: 0.9095477386934674\n",
      "07/24/2020 01:04:45 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8929    0.9434    0.9174       106\n",
      "           1     0.9310    0.8710    0.9000        93\n",
      "\n",
      "    accuracy                         0.9095       199\n",
      "   macro avg     0.9119    0.9072    0.9087       199\n",
      "weighted avg     0.9107    0.9095    0.9093       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.3293): 100%|██████████| 50/50 [00:47<00:00,  1.06it/s]\n",
      "Train epoch 2/2 (Cur. train loss: 0.5483):  40%|████      | 20/50 [00:16<00:24,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.87it/s]\n",
      "07/24/2020 01:05:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 120 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:05:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:05:13 - INFO - farm.eval -   loss: 0.4065816246684472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:05:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:05:13 - INFO - farm.eval -   acc: 0.9396984924623115\n",
      "07/24/2020 01:05:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9519    0.9340    0.9429       106\n",
      "           1     0.9263    0.9462    0.9362        93\n",
      "\n",
      "    accuracy                         0.9397       199\n",
      "   macro avg     0.9391    0.9401    0.9395       199\n",
      "weighted avg     0.9400    0.9397    0.9397       199\n",
      "\n",
      "Train epoch 2/2 (Cur. train loss: 0.0005): 100%|██████████| 50/50 [00:43<00:00,  1.15it/s]\n",
      "Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   loss: 0.31341663928691277\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   acc: 0.9458917835671342\n",
      "07/24/2020 01:05:44 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9772    0.9245    0.9501       278\n",
      "           1     0.9110    0.9729    0.9409       221\n",
      "\n",
      "    accuracy                         0.9459       499\n",
      "   macro avg     0.9441    0.9487    0.9455       499\n",
      "weighted avg     0.9479    0.9459    0.9460       499\n",
      "\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:05:48 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Crossvalidation: Fold 2 ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:05:49 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ehsanmontazeri/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "07/24/2020 01:05:53 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:05:53 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:05:53 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/24/2020 01:05:53 - INFO - transformers.modeling_utils -   loading weights file /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin from cache at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin\n",
      "07/24/2020 01:05:58 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 01:05:58 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/language_model.bin.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/24/2020 01:05:58 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.prediction_head -   Loading prediction head from /home/ehsanmontazeri/Allianz_NLP/esg_data_pipeline/esg_data_pipeline/saved_models/relevance_roberta/prediction_head_0.bin\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/24/2020 01:05:58 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 15.0, 'num_training_steps': 150}'\n",
      "07/24/2020 01:05:58 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.4938):  60%|██████    | 30/50 [00:25<00:16,  1.20it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   loss: 0.40613595654617\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   acc: 0.8944723618090452\n",
      "07/24/2020 01:06:28 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.9143    0.9014       105\n",
      "           1     0.9011    0.8723    0.8865        94\n",
      "\n",
      "    accuracy                         0.8945       199\n",
      "   macro avg     0.8950    0.8933    0.8939       199\n",
      "weighted avg     0.8947    0.8945    0.8944       199\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.0047): 100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Train epoch 1/2 (Cur. train loss: 0.2472):  20%|██        | 10/50 [00:08<00:32,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.87it/s]\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   loss: 0.2329711967976249\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   acc: 0.9396984924623115\n",
      "07/24/2020 01:06:55 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9346    0.9524    0.9434       105\n",
      "           1     0.9457    0.9255    0.9355        94\n",
      "\n",
      "    accuracy                         0.9397       199\n",
      "   macro avg     0.9401    0.9390    0.9394       199\n",
      "weighted avg     0.9398    0.9397    0.9397       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.0016):  80%|████████  | 40/50 [00:35<00:08,  1.24it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 90 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   loss: 0.25121793615159077\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   acc: 0.9246231155778895\n",
      "07/24/2020 01:07:23 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8947    0.9714    0.9315       105\n",
      "           1     0.9647    0.8723    0.9162        94\n",
      "\n",
      "    accuracy                         0.9246       199\n",
      "   macro avg     0.9297    0.9219    0.9239       199\n",
      "weighted avg     0.9278    0.9246    0.9243       199\n",
      "\n",
      "Train epoch 1/2 (Cur. train loss: 0.0061): 100%|██████████| 50/50 [00:47<00:00,  1.06it/s]\n",
      "Train epoch 2/2 (Cur. train loss: 0.0013):  40%|████      | 20/50 [00:16<00:24,  1.25it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n",
      "07/24/2020 01:07:50 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 120 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:07:50 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:07:50 - INFO - farm.eval -   loss: 0.24493161802315833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 01:07:50 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:07:50 - INFO - farm.eval -   acc: 0.9447236180904522\n",
      "07/24/2020 01:07:50 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9519    0.9429    0.9474       105\n",
      "           1     0.9368    0.9468    0.9418        94\n",
      "\n",
      "    accuracy                         0.9447       199\n",
      "   macro avg     0.9444    0.9448    0.9446       199\n",
      "weighted avg     0.9448    0.9447    0.9447       199\n",
      "\n",
      "Train epoch 2/2 (Cur. train loss: 0.0190): 100%|██████████| 50/50 [00:43<00:00,  1.14it/s]\n",
      "Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   loss: 0.11263696460360026\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   task_name: text_classification\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   acc: 0.9678714859437751\n",
      "07/24/2020 01:08:22 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9748    0.9713       278\n",
      "           1     0.9679    0.9591    0.9635       220\n",
      "\n",
      "    accuracy                         0.9679       498\n",
      "   macro avg     0.9679    0.9670    0.9674       498\n",
      "weighted avg     0.9679    0.9679    0.9679       498\n",
      "\n",
      "Evaluating: 100%|██████████| 13/13 [00:03<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ RESULT_CV -- 3 folds ############\n",
      "Mean F1:  93.9, std F1: 0.006\n",
      "Mean recall:  93.2, std recall: 0.004\n",
      "Mean accuracy:  94.3, std accuracy; 0.006\n",
      "Mean precision:  94.6, std  precision: 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! CV mode does not save a checkpoint, it is only used for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the saved model and test it on some real examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farm.infer import Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:54:45 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "07/24/2020 03:54:45 - INFO - transformers.modeling_utils -   loading weights file saved_models/test_farm/language_model.bin from cache at saved_models/test_farm/language_model.bin\n",
      "07/24/2020 03:54:51 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "07/24/2020 03:54:51 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at saved_models/test_farm/language_model.bin.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "07/24/2020 03:54:51 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/24/2020 03:54:51 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/24/2020 03:54:51 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/24/2020 03:54:51 - INFO - farm.modeling.prediction_head -   Loading prediction head from saved_models/test_farm/prediction_head_0.bin\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   Model name 'saved_models/test_farm' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'saved_models/test_farm' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   Didn't find file saved_models/test_farm/added_tokens.json. We won't load it.\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   Didn't find file saved_models/test_farm/tokenizer.json. We won't load it.\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file saved_models/test_farm/vocab.json\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file saved_models/test_farm/merges.txt\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file saved_models/test_farm/special_tokens_map.json\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file saved_models/test_farm/tokenizer_config.json\n",
      "07/24/2020 03:54:51 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "07/24/2020 03:54:51 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "07/24/2020 03:54:51 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "07/24/2020 03:54:52 - INFO - farm.infer -   Got ya 15 parallel workers to do inference ...\n",
      "07/24/2020 03:54:52 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "07/24/2020 03:54:52 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "07/24/2020 03:54:52 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n",
      "07/24/2020 03:54:52 - INFO - farm.infer -                               \n",
      "07/24/2020 03:55:32 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:55:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the climate commitment scenario considered?\n",
      " \ttext_b: AGL’s approach to transitioning to a low-carbon future is set out within the AGL Greenhouse Gas Policy. This policy acknowledges that Australia is moving to a carbon-constrained future and provides a framework within which greenhouse gas reduction activities will be structured, presenting a pathway for the gradual decarbonisation of AGL’s generation portfolio by mid-century. The commitments of AGL within this policy are not inconsistent with the goal of the Paris Agreement to limit warming to below 2 degrees celsius above pre-industrial levels.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġclimate', 'Ġcommitment', 'Ġscenario', 'Ġconsidered', '?']\n",
      " \ttokens_b: ['AG', 'L', 'âĢ', 'Ļ', 's', 'Ġapproach', 'Ġto', 'Ġtransitioning', 'Ġto', 'Ġa', 'Ġlow', '-', 'carbon', 'Ġfuture', 'Ġis', 'Ġset', 'Ġout', 'Ġwithin', 'Ġthe', 'ĠA', 'GL', 'ĠGreen', 'house', 'ĠGas', 'ĠPolicy', '.', 'ĠThis', 'Ġpolicy', 'Ġacknowledges', 'Ġthat', 'ĠAustralia', 'Ġis', 'Ġmoving', 'Ġto', 'Ġa', 'Ġcarbon', '-', 'con', 'str', 'ained', 'Ġfuture', 'Ġand', 'Ġprovides', 'Ġa', 'Ġframework', 'Ġwithin', 'Ġwhich', 'Ġgreenhouse', 'Ġgas', 'Ġreduction', 'Ġactivities', 'Ġwill', 'Ġbe', 'Ġstructured', ',', 'Ġpresenting', 'Ġa', 'Ġpathway', 'Ġfor', 'Ġthe', 'Ġgradual', 'Ġdec', 'arbon', 'isation', 'Ġof', 'ĠA', 'GL', 'âĢ', 'Ļ', 's', 'Ġgeneration', 'Ġportfolio', 'Ġby', 'Ġmid', '-', 'century', '.', 'ĠThe', 'Ġcommitments', 'Ġof', 'ĠA', 'GL', 'Ġwithin', 'Ġthis', 'Ġpolicy', 'Ġare', 'Ġnot', 'Ġinconsistent', 'Ġwith', 'Ġthe', 'Ġgoal', 'Ġof', 'Ġthe', 'ĠParis', 'ĠAgreement', 'Ġto', 'Ġlimit', 'Ġwarming', 'Ġto', 'Ġbelow', 'Ġ2', 'Ġdegrees', 'Ġc', 'elsius', 'Ġabove', 'Ġpre', '-', 'industrial', 'Ġlevels', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 2147, 2720, 5665, 1687, 116, 2, 2, 3450, 574, 17, 27, 29, 1548, 7, 26135, 7, 10, 614, 12, 23612, 499, 16, 278, 66, 624, 5, 83, 10020, 1628, 3138, 5664, 6275, 4, 152, 714, 17748, 14, 1221, 16, 1375, 7, 10, 4363, 12, 3865, 6031, 7153, 499, 8, 1639, 10, 7208, 624, 61, 11832, 1123, 4878, 1713, 40, 28, 16697, 6, 10864, 10, 19165, 13, 5, 16677, 5044, 40035, 3258, 9, 83, 10020, 17, 27, 29, 2706, 2819, 30, 1084, 12, 11046, 4, 20, 9116, 9, 83, 10020, 624, 42, 714, 32, 45, 16611, 19, 5, 724, 9, 5, 2201, 8759, 7, 3000, 8232, 7, 874, 132, 4176, 740, 46970, 1065, 1198, 12, 27739, 1389, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:55:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the climate commitment scenario considered?\n",
      " \ttext_b: AGL’s approach to transitioning to a low-carbon future is set out within the AGL Greenhouse Gas Policy. This policy acknowledges that Australia is moving to a carbon-constrained future and provides a framework within which greenhouse gas reduction activities will be structured, presenting a pathway for the gradual decarbonisation of AGL’s generation portfolio by mid-century. The commitments of AGL within this policy are not inconsistent with the goal of the Paris Agreement to limit warming to below 2 degrees celsius above pre-industrial levels.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġclimate', 'Ġcommitment', 'Ġscenario', 'Ġconsidered', '?']\n",
      " \ttokens_b: ['AG', 'L', 'âĢ', 'Ļ', 's', 'Ġapproach', 'Ġto', 'Ġtransitioning', 'Ġto', 'Ġa', 'Ġlow', '-', 'carbon', 'Ġfuture', 'Ġis', 'Ġset', 'Ġout', 'Ġwithin', 'Ġthe', 'ĠA', 'GL', 'ĠGreen', 'house', 'ĠGas', 'ĠPolicy', '.', 'ĠThis', 'Ġpolicy', 'Ġacknowledges', 'Ġthat', 'ĠAustralia', 'Ġis', 'Ġmoving', 'Ġto', 'Ġa', 'Ġcarbon', '-', 'con', 'str', 'ained', 'Ġfuture', 'Ġand', 'Ġprovides', 'Ġa', 'Ġframework', 'Ġwithin', 'Ġwhich', 'Ġgreenhouse', 'Ġgas', 'Ġreduction', 'Ġactivities', 'Ġwill', 'Ġbe', 'Ġstructured', ',', 'Ġpresenting', 'Ġa', 'Ġpathway', 'Ġfor', 'Ġthe', 'Ġgradual', 'Ġdec', 'arbon', 'isation', 'Ġof', 'ĠA', 'GL', 'âĢ', 'Ļ', 's', 'Ġgeneration', 'Ġportfolio', 'Ġby', 'Ġmid', '-', 'century', '.', 'ĠThe', 'Ġcommitments', 'Ġof', 'ĠA', 'GL', 'Ġwithin', 'Ġthis', 'Ġpolicy', 'Ġare', 'Ġnot', 'Ġinconsistent', 'Ġwith', 'Ġthe', 'Ġgoal', 'Ġof', 'Ġthe', 'ĠParis', 'ĠAgreement', 'Ġto', 'Ġlimit', 'Ġwarming', 'Ġto', 'Ġbelow', 'Ġ2', 'Ġdegrees', 'Ġc', 'elsius', 'Ġabove', 'Ġpre', '-', 'industrial', 'Ġlevels', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 2147, 2720, 5665, 1687, 116, 2, 2, 3450, 574, 17, 27, 29, 1548, 7, 26135, 7, 10, 614, 12, 23612, 499, 16, 278, 66, 624, 5, 83, 10020, 1628, 3138, 5664, 6275, 4, 152, 714, 17748, 14, 1221, 16, 1375, 7, 10, 4363, 12, 3865, 6031, 7153, 499, 8, 1639, 10, 7208, 624, 61, 11832, 1123, 4878, 1713, 40, 28, 16697, 6, 10864, 10, 19165, 13, 5, 16677, 5044, 40035, 3258, 9, 83, 10020, 17, 27, 29, 2706, 2819, 30, 1084, 12, 11046, 4, 20, 9116, 9, 83, 10020, 624, 42, 714, 32, 45, 16611, 19, 5, 724, 9, 5, 2201, 8759, 7, 3000, 8232, 7, 874, 132, 4176, 740, 46970, 1065, 1198, 12, 27739, 1389, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/24/2020 03:55:35 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:55:35 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the climate commitment scenario considered?\n",
      " \ttext_b: 1. There is a transparent procedure implemented in the Company that provides the shareholders with the opportunity to send questions to the Chairman of the Board of Directors and express their position.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġclimate', 'Ġcommitment', 'Ġscenario', 'Ġconsidered', '?']\n",
      " \ttokens_b: ['1', '.', 'ĠThere', 'Ġis', 'Ġa', 'Ġtransparent', 'Ġprocedure', 'Ġimplemented', 'Ġin', 'Ġthe', 'ĠCompany', 'Ġthat', 'Ġprovides', 'Ġthe', 'Ġshareholders', 'Ġwith', 'Ġthe', 'Ġopportunity', 'Ġto', 'Ġsend', 'Ġquestions', 'Ġto', 'Ġthe', 'ĠChairman', 'Ġof', 'Ġthe', 'ĠBoard', 'Ġof', 'ĠDirectors', 'Ġand', 'Ġexpress', 'Ġtheir', 'Ġposition', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 2147, 2720, 5665, 1687, 116, 2, 2, 134, 4, 345, 16, 10, 8818, 7089, 6264, 11, 5, 1260, 14, 1639, 5, 4071, 19, 5, 945, 7, 2142, 1142, 7, 5, 3356, 9, 5, 1785, 9, 12131, 8, 5486, 49, 737, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:55:35 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the climate commitment scenario considered?\n",
      " \ttext_b: 1. There is a transparent procedure implemented in the Company that provides the shareholders with the opportunity to send questions to the Chairman of the Board of Directors and express their position.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġclimate', 'Ġcommitment', 'Ġscenario', 'Ġconsidered', '?']\n",
      " \ttokens_b: ['1', '.', 'ĠThere', 'Ġis', 'Ġa', 'Ġtransparent', 'Ġprocedure', 'Ġimplemented', 'Ġin', 'Ġthe', 'ĠCompany', 'Ġthat', 'Ġprovides', 'Ġthe', 'Ġshareholders', 'Ġwith', 'Ġthe', 'Ġopportunity', 'Ġto', 'Ġsend', 'Ġquestions', 'Ġto', 'Ġthe', 'ĠChairman', 'Ġof', 'Ġthe', 'ĠBoard', 'Ġof', 'ĠDirectors', 'Ġand', 'Ġexpress', 'Ġtheir', 'Ġposition', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 2147, 2720, 5665, 1687, 116, 2, 2, 134, 4, 345, 16, 10, 8818, 7089, 6264, 11, 5, 1260, 14, 1639, 5, 4071, 19, 5, 945, 7, 2142, 1142, 7, 5, 3356, 9, 5, 1785, 9, 12131, 8, 5486, 49, 737, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/24/2020 03:55:37 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:55:37 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the target carbon reduction in percentage?\n",
      " \ttext_b: In 2018 we signed the Business in the Community Ireland Low Carbon Pledge, agreeing to reduce greenhouse gas emissions by half by 2030. We also co-chair the Transition to a Low Carbon Economy Group, comprising representatives from some of the companies who hold the Businesses Working Responsibly Mark. The Group meets regularly to agree collaborative action to improve the sustainability of the Irish business sector.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġcarbon', 'Ġreduction', 'Ġin', 'Ġpercentage', '?']\n",
      " \ttokens_b: ['In', 'Ġ2018', 'Ġwe', 'Ġsigned', 'Ġthe', 'ĠBusiness', 'Ġin', 'Ġthe', 'ĠCommunity', 'ĠIreland', 'ĠLow', 'ĠCarbon', 'ĠPledge', ',', 'Ġagreeing', 'Ġto', 'Ġreduce', 'Ġgreenhouse', 'Ġgas', 'Ġemissions', 'Ġby', 'Ġhalf', 'Ġby', 'Ġ2030', '.', 'ĠWe', 'Ġalso', 'Ġco', '-', 'chair', 'Ġthe', 'ĠTransition', 'Ġto', 'Ġa', 'ĠLow', 'ĠCarbon', 'ĠEconomy', 'ĠGroup', ',', 'Ġcomprising', 'Ġrepresentatives', 'Ġfrom', 'Ġsome', 'Ġof', 'Ġthe', 'Ġcompanies', 'Ġwho', 'Ġhold', 'Ġthe', 'ĠBusiness', 'es', 'ĠWorking', 'ĠRespons', 'ibly', 'ĠMark', '.', 'ĠThe', 'ĠGroup', 'Ġmeets', 'Ġregularly', 'Ġto', 'Ġagree', 'Ġcollaborative', 'Ġaction', 'Ġto', 'Ġimprove', 'Ġthe', 'Ġsustainability', 'Ġof', 'Ġthe', 'ĠIrish', 'Ġbusiness', 'Ġsector', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4363, 4878, 11, 3164, 116, 2, 2, 1121, 199, 52, 1419, 5, 2090, 11, 5, 2573, 2487, 6207, 17962, 37657, 6, 14176, 7, 1888, 11832, 1123, 5035, 30, 457, 30, 12060, 4, 166, 67, 1029, 12, 13599, 5, 34235, 7, 10, 6207, 17962, 15735, 826, 6, 14096, 4844, 31, 103, 9, 5, 451, 54, 946, 5, 2090, 293, 11214, 25714, 19031, 1190, 4, 20, 826, 6616, 4595, 7, 2854, 14473, 814, 7, 1477, 5, 11128, 9, 5, 3445, 265, 1293, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:55:37 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the target carbon reduction in percentage?\n",
      " \ttext_b: In 2018 we signed the Business in the Community Ireland Low Carbon Pledge, agreeing to reduce greenhouse gas emissions by half by 2030. We also co-chair the Transition to a Low Carbon Economy Group, comprising representatives from some of the companies who hold the Businesses Working Responsibly Mark. The Group meets regularly to agree collaborative action to improve the sustainability of the Irish business sector.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġcarbon', 'Ġreduction', 'Ġin', 'Ġpercentage', '?']\n",
      " \ttokens_b: ['In', 'Ġ2018', 'Ġwe', 'Ġsigned', 'Ġthe', 'ĠBusiness', 'Ġin', 'Ġthe', 'ĠCommunity', 'ĠIreland', 'ĠLow', 'ĠCarbon', 'ĠPledge', ',', 'Ġagreeing', 'Ġto', 'Ġreduce', 'Ġgreenhouse', 'Ġgas', 'Ġemissions', 'Ġby', 'Ġhalf', 'Ġby', 'Ġ2030', '.', 'ĠWe', 'Ġalso', 'Ġco', '-', 'chair', 'Ġthe', 'ĠTransition', 'Ġto', 'Ġa', 'ĠLow', 'ĠCarbon', 'ĠEconomy', 'ĠGroup', ',', 'Ġcomprising', 'Ġrepresentatives', 'Ġfrom', 'Ġsome', 'Ġof', 'Ġthe', 'Ġcompanies', 'Ġwho', 'Ġhold', 'Ġthe', 'ĠBusiness', 'es', 'ĠWorking', 'ĠRespons', 'ibly', 'ĠMark', '.', 'ĠThe', 'ĠGroup', 'Ġmeets', 'Ġregularly', 'Ġto', 'Ġagree', 'Ġcollaborative', 'Ġaction', 'Ġto', 'Ġimprove', 'Ġthe', 'Ġsustainability', 'Ġof', 'Ġthe', 'ĠIrish', 'Ġbusiness', 'Ġsector', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4363, 4878, 11, 3164, 116, 2, 2, 1121, 199, 52, 1419, 5, 2090, 11, 5, 2573, 2487, 6207, 17962, 37657, 6, 14176, 7, 1888, 11832, 1123, 5035, 30, 457, 30, 12060, 4, 166, 67, 1029, 12, 13599, 5, 34235, 7, 10, 6207, 17962, 15735, 826, 6, 14096, 4844, 31, 103, 9, 5, 451, 54, 946, 5, 2090, 293, 11214, 25714, 19031, 1190, 4, 20, 826, 6616, 4595, 7, 2854, 14473, 814, 7, 1477, 5, 11128, 9, 5, 3445, 265, 1293, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/24/2020 03:55:38 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/24/2020 03:55:38 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the target carbon reduction in percentage?\n",
      " \ttext_b: In 2017, the program was extended to Abu Dhabi in the Middle East and Africa region, to two OMV Petrom (Romania) sites and eight main contractors from Upstream and Downstream in OMV Petrom. Interviews and focus group discussions with the management and employees at all levels of the business have provided the current picture of our safety culture and helped to understand the origins of our daily decisions and behavior. The program continued with train- ing of selected employees, local management and supervisors in the chosen locations.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġcarbon', 'Ġreduction', 'Ġin', 'Ġpercentage', '?']\n",
      " \ttokens_b: ['In', 'Ġ2017', ',', 'Ġthe', 'Ġprogram', 'Ġwas', 'Ġextended', 'Ġto', 'ĠAbu', 'ĠDhabi', 'Ġin', 'Ġthe', 'ĠMiddle', 'ĠEast', 'Ġand', 'ĠAfrica', 'Ġregion', ',', 'Ġto', 'Ġtwo', 'ĠOM', 'V', 'ĠPet', 'rom', 'Ġ(', 'Roman', 'ia', ')', 'Ġsites', 'Ġand', 'Ġeight', 'Ġmain', 'Ġcontractors', 'Ġfrom', 'ĠUp', 'stream', 'Ġand', 'ĠDown', 'stream', 'Ġin', 'ĠOM', 'V', 'ĠPet', 'rom', '.', 'ĠInterview', 's', 'Ġand', 'Ġfocus', 'Ġgroup', 'Ġdiscussions', 'Ġwith', 'Ġthe', 'Ġmanagement', 'Ġand', 'Ġemployees', 'Ġat', 'Ġall', 'Ġlevels', 'Ġof', 'Ġthe', 'Ġbusiness', 'Ġhave', 'Ġprovided', 'Ġthe', 'Ġcurrent', 'Ġpicture', 'Ġof', 'Ġour', 'Ġsafety', 'Ġculture', 'Ġand', 'Ġhelped', 'Ġto', 'Ġunderstand', 'Ġthe', 'Ġorigins', 'Ġof', 'Ġour', 'Ġdaily', 'Ġdecisions', 'Ġand', 'Ġbehavior', '.', 'ĠThe', 'Ġprogram', 'Ġcontinued', 'Ġwith', 'Ġtrain', '-', 'Ġing', 'Ġof', 'Ġselected', 'Ġemployees', ',', 'Ġlocal', 'Ġmanagement', 'Ġand', 'Ġsupervisors', 'Ġin', 'Ġthe', 'Ġchosen', 'Ġlocations', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4363, 4878, 11, 3164, 116, 2, 2, 1121, 193, 6, 5, 586, 21, 3112, 7, 4896, 13125, 11, 5, 2367, 953, 8, 1327, 976, 6, 7, 80, 23765, 846, 5106, 5638, 36, 38962, 493, 43, 3091, 8, 799, 1049, 9617, 31, 3105, 8656, 8, 5818, 8656, 11, 23765, 846, 5106, 5638, 4, 21902, 29, 8, 1056, 333, 4404, 19, 5, 1052, 8, 1321, 23, 70, 1389, 9, 5, 265, 33, 1286, 5, 595, 2170, 9, 84, 1078, 2040, 8, 1147, 7, 1346, 5, 18863, 9, 84, 1230, 2390, 8, 3650, 4, 20, 586, 1143, 19, 2341, 12, 21691, 9, 3919, 1321, 6, 400, 1052, 8, 19971, 11, 5, 4986, 3237, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 03:55:38 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the target carbon reduction in percentage?\n",
      " \ttext_b: In 2017, the program was extended to Abu Dhabi in the Middle East and Africa region, to two OMV Petrom (Romania) sites and eight main contractors from Upstream and Downstream in OMV Petrom. Interviews and focus group discussions with the management and employees at all levels of the business have provided the current picture of our safety culture and helped to understand the origins of our daily decisions and behavior. The program continued with train- ing of selected employees, local management and supervisors in the chosen locations.\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġcarbon', 'Ġreduction', 'Ġin', 'Ġpercentage', '?']\n",
      " \ttokens_b: ['In', 'Ġ2017', ',', 'Ġthe', 'Ġprogram', 'Ġwas', 'Ġextended', 'Ġto', 'ĠAbu', 'ĠDhabi', 'Ġin', 'Ġthe', 'ĠMiddle', 'ĠEast', 'Ġand', 'ĠAfrica', 'Ġregion', ',', 'Ġto', 'Ġtwo', 'ĠOM', 'V', 'ĠPet', 'rom', 'Ġ(', 'Roman', 'ia', ')', 'Ġsites', 'Ġand', 'Ġeight', 'Ġmain', 'Ġcontractors', 'Ġfrom', 'ĠUp', 'stream', 'Ġand', 'ĠDown', 'stream', 'Ġin', 'ĠOM', 'V', 'ĠPet', 'rom', '.', 'ĠInterview', 's', 'Ġand', 'Ġfocus', 'Ġgroup', 'Ġdiscussions', 'Ġwith', 'Ġthe', 'Ġmanagement', 'Ġand', 'Ġemployees', 'Ġat', 'Ġall', 'Ġlevels', 'Ġof', 'Ġthe', 'Ġbusiness', 'Ġhave', 'Ġprovided', 'Ġthe', 'Ġcurrent', 'Ġpicture', 'Ġof', 'Ġour', 'Ġsafety', 'Ġculture', 'Ġand', 'Ġhelped', 'Ġto', 'Ġunderstand', 'Ġthe', 'Ġorigins', 'Ġof', 'Ġour', 'Ġdaily', 'Ġdecisions', 'Ġand', 'Ġbehavior', '.', 'ĠThe', 'Ġprogram', 'Ġcontinued', 'Ġwith', 'Ġtrain', '-', 'Ġing', 'Ġof', 'Ġselected', 'Ġemployees', ',', 'Ġlocal', 'Ġmanagement', 'Ġand', 'Ġsupervisors', 'Ġin', 'Ġthe', 'Ġchosen', 'Ġlocations', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4363, 4878, 11, 3164, 116, 2, 2, 1121, 193, 6, 5, 586, 21, 3112, 7, 4896, 13125, 11, 5, 2367, 953, 8, 1327, 976, 6, 7, 80, 23765, 846, 5106, 5638, 36, 38962, 493, 43, 3091, 8, 799, 1049, 9617, 31, 3105, 8656, 8, 5818, 8656, 11, 23765, 846, 5106, 5638, 4, 21902, 29, 8, 1056, 333, 4404, 19, 5, 1052, 8, 1321, 23, 70, 1389, 9, 5, 265, 33, 1286, 5, 595, 2170, 9, 84, 1078, 2040, 8, 1147, 7, 1346, 5, 18863, 9, 84, 1230, 2390, 8, 3650, 4, 20, 586, 1143, 19, 2341, 12, 21691, 9, 3919, 1321, 6, 400, 1052, 8, 19971, 11, 5, 4986, 3237, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Inferencer.load(file_config.saved_models_dir, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_results(example):\n",
    "    result = model.inference_from_dicts(dicts=[example], return_json=False)\n",
    "    result = \"Relevant\" if result[0][\"predictions\"][0][\"label\"] == \"1\" else \"Not Relevant\"\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.71 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "example = {\n",
    "    \"text\": \"What is the climate commitment scenario considered?\",\n",
    "    \"text_b\": \"AGL’s approach to transitioning to a low-carbon future is set out within \"\n",
    "    \"the AGL Greenhouse Gas Policy. This policy acknowledges that Australia is moving to a \"\n",
    "    \"carbon-constrained future and provides a framework within which greenhouse gas reduction \"\n",
    "    \"activities will be structured, presenting a pathway for the gradual decarbonisation of \"\n",
    "    \"AGL’s generation portfolio by mid-century. The commitments of AGL within this policy are \"\n",
    "    \"not inconsistent with the goal of the Paris Agreement to limit warming to below 2 degrees \"\n",
    "    \"celsius above pre-industrial levels.\",\n",
    "}\n",
    "\n",
    "get_inference_results(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.40 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Relevant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "example = {\n",
    "    \"text\": \"What is the climate commitment scenario considered?\",\n",
    "    \"text_b\": \"1. There is a transparent procedure implemented in the Company that provides the \"\n",
    "    \"shareholders with the opportunity to send questions to the Chairman of the Board of Directors \"\n",
    "    \"and express their position.\",\n",
    "}\n",
    "get_inference_results(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.69 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "example = {\n",
    "    \"text\": \"What is the target carbon reduction in percentage?\",\n",
    "    \"text_b\": \"In 2018 we signed the Business in the Community Ireland Low Carbon Pledge, \"\n",
    "    \"agreeing to reduce greenhouse gas emissions by half by 2030. We also co-chair the Transition to a \"\n",
    "    \"Low Carbon Economy Group, comprising representatives from some of the companies who hold the \"\n",
    "    \"Businesses Working Responsibly Mark. The Group meets regularly to agree collaborative action to \"\n",
    "    \"improve the sustainability of the Irish business sector.\",\n",
    "}\n",
    "get_inference_results(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.04 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Relevant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "example = {\n",
    "    \"text\": \"What is the target carbon reduction in percentage?\",\n",
    "    \"text_b\": \"In 2017, the program was extended to Abu Dhabi in the Middle East and Africa region, \"\n",
    "    \"to two OMV Petrom (Romania) sites and eight main contractors from Upstream and \"\n",
    "    \"Downstream in OMV Petrom. Interviews and focus group discussions with the management \"\n",
    "    \"and employees at all levels of the business have provided the current picture of our \"\n",
    "    \"safety culture and helped to understand the origins of our daily decisions and behavior. \"\n",
    "    \"The program continued with train- ing of selected employees, local management and supervisors \"\n",
    "    \"in the chosen locations.\",\n",
    "}\n",
    "get_inference_results(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
