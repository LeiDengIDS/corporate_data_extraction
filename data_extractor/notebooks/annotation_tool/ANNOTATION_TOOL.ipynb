{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNOTATION TOOL\n",
    "This tool provides some interfaces for evaluating the kpi inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Setup the Tool\n",
    "As a first step, we need some basic imports and have to set a few information which we will need throughout the annotatation process.\\\n",
    "Execute the following cell in order to import all the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import annotation_tool as tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the cell has successfully executed, provide the asked information in the next cell and run and run the cell afterwards. This will start the first step of the tool and provides you with the possibility to select the KPIs you are interested in. It is possible to later change the selected KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c9a732803a4b60913877d00aacd2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set the name of the annotator an run the cell.\n",
    "tool.annotator = \"Max\" \n",
    "\n",
    "tool.select_your_kpi_of_interest()",
    "tool.annotation_path = '/opt/app-root/src/corporate_data_pipeline/NLP_ANNOTATION_TOOL'",
    "tool.output_path = '/opt/app-root/src/corporate_data_pipeline/NLP_ANNOTATION_TOOL/output",
    "tool.input_path = '/opt/app-root/src/corporate_data_pipeline/NLP_ANNOTATION_TOOL/input'",
    "tool.kpi_mapping_fpath = '/app/data/ESG/input/kpi_mapping/kpi_mapping.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Select the report to analyze\n",
    "With the KPIs selected we will chose the report for analyzing the KPI inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e1d33312144714a2527ddfd7ff6fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': \"Select(description='Available results:â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool.select_the_report_to_analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some more information about the chosen report and the related company. Please update the following variables and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.company = \"General Motors Company\"\n",
    "tool.year = 2019\n",
    "\n",
    "\n",
    "tool.sector = \"Automotive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Annotate the selected PDF\n",
    "Now you will loop through the given answers for a question. Select the highest rank with a right answer.\n",
    "You also have the possibility to correct an incorrectly chosen paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7407209b61d9431187672afcc9cef0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648c3309ae074a339fde20b3f94b63fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool.lets_go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export outcome\n",
    "After finishing the annotation session export your results to an excel file. Your results will be added into the existing annotations.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool.export_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In output file year, company and sector are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation Notes:\n",
    "* No kpi_ids in the inference output\n",
    "* No answer has no \"no answer\"-score\n",
    "* How to handle no answer in the annotations, if the answer is really not in the pdf? This is also an information, but probably can not be handled yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
